{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# First, load a results file\n",
    "RANKINGS_PATH = \"../rankings.csv\"\n",
    "rankings = pd.read_csv(RANKINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter sets for which to check\n",
    "PARAMS = [(1, 20, 500, 500, 50, 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ranking for the uninformed method\n",
    "# METHOD: Purely peak-performance based. If that is the same, choose lowest variation number first where sequential < omp < cuda\n",
    "uninformed_ranking = [\n",
    "    (\"home_desktop\", \"CUDA_GPU1\", 1), # 10070.0\n",
    "    \n",
    "    (\"DAS5\", \"CUDA_GPU1\", 1), # 6691.0\n",
    "    \n",
    "    (\"home_desktop\", \"OMP_CPU5\", 16), # 460.8 (simd, only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU5\", 32), # 460.8 (simd, only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU8\", 16), # 460.8 (simd)\n",
    "    (\"home_desktop\", \"OMP_CPU8\", 32), # 460.8 (simd)\n",
    "    \n",
    "    (\"DAS5\", \"OMP_CPU5\", 32), # 307.2 (simd, only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU8\", 32), # 307.2 (simd)\n",
    "    \n",
    "    (\"lisa\", \"OMP_CPU5\", 16), # 256 (simd, only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU5\", 32), # 256 (simd, only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU8\", 16), # 256 (simd)\n",
    "    (\"lisa\", \"OMP_CPU8\", 32), # 256 (simd)\n",
    "    \n",
    "    (\"home_desktop\", \"OMP_CPU5\", 8), # 230.4 (simd, only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU8\", 8), # 230.4 (simd)\n",
    "    \n",
    "    (\"DAS5\", \"OMP_CPU5\", 16), # 153.6 (simd, only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU8\", 16), # 153.6 (simd)\n",
    "    \n",
    "    (\"lisa\", \"OMP_CPU5\", 8), # 128 (simd, only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU8\", 8), # 128 (simd)\n",
    "    \n",
    "    (\"home_desktop\", \"OMP_CPU1\", 16), # 115.2 (only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU1\", 32), # 115.2 (only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU3\", 16), # 115.2\n",
    "    (\"home_desktop\", \"OMP_CPU3\", 32), # 115.2\n",
    "    (\"home_desktop\", \"OMP_CPU5\", 4), # 115.2 (simd, only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU7\", 16), # 115.2\n",
    "    (\"home_desktop\", \"OMP_CPU7\", 32), # 115.2\n",
    "    (\"home_desktop\", \"OMP_CPU8\", 4), # 115.2 (simd)\n",
    "    \n",
    "    (\"DAS5\", \"OMP_CPU1\", 32), # 76.8 (only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU3\", 32), # 76.8\n",
    "    (\"DAS5\", \"OMP_CPU5\", 8), # 76.8 (simd, only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU7\", 32), # 76.8\n",
    "    (\"DAS5\", \"OMP_CPU8\", 8), # 76.8 (simd)\n",
    "    \n",
    "    (\"lisa\", \"OMP_CPU1\", 32), # 64 (only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU3\", 32), # 64\n",
    "    (\"lisa\", \"OMP_CPU5\", 4), # 64 (simd, only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU7\", 32), # 64\n",
    "    (\"lisa\", \"OMP_CPU8\", 4), # 64 (simd)\n",
    "    \n",
    "    (\"home_desktop\", \"OMP_CPU1\", 8), # 57.6 (only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU3\", 8), # 57.6\n",
    "    (\"home_desktop\", \"OMP_CPU5\", 2), # 57.6 (simd, only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU7\", 8), # 57.6\n",
    "    (\"home_desktop\", \"OMP_CPU8\", 2), # 57.6 (simd)\n",
    "    \n",
    "    (\"DAS5\", \"OMP_CPU1\", 16), # 38.4 (only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU3\", 16), # 38.4\n",
    "    (\"DAS5\", \"OMP_CPU5\", 4), # 38.4 (simd, only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU7\", 16), # 38.4\n",
    "    (\"DAS5\", \"OMP_CPU8\", 4), # 38.4 (simd)\n",
    "    \n",
    "    (\"lisa\", \"OMP_CPU1\", 16), # 32 (only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU3\", 16), # 32\n",
    "    (\"lisa\", \"OMP_CPU5\", 2), # 32 (simd, only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU7\", 16), # 32\n",
    "    (\"lisa\", \"OMP_CPU8\", 2), # 32 (simd)\n",
    "    \n",
    "    (\"home_desktop\", \"OMP_CPU1\", 4), # 28.8 (only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU3\", 4), # 28.8\n",
    "    (\"home_desktop\", \"OMP_CPU4\", 1), # 28.8\n",
    "    (\"home_desktop\", \"OMP_CPU7\", 4), # 28.8\n",
    "    \n",
    "    (\"DAS5\", \"OMP_CPU1\", 8), # 19.2 (only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU3\", 8), # 19.2\n",
    "    (\"DAS5\", \"OMP_CPU5\", 2), # 19.2 (simd, only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU7\", 8), # 19.2\n",
    "    (\"DAS5\", \"OMP_CPU8\", 2), # 19.2 (simd)\n",
    "    \n",
    "    (\"lisa\", \"OMP_CPU1\", 8), # 16 (only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU3\", 8), # 16\n",
    "    (\"lisa\", \"OMP_CPU4\", 1), # 16\n",
    "    (\"lisa\", \"OMP_CPU7\", 8), # 16\n",
    "    \n",
    "    (\"home_desktop\", \"OMP_CPU1\", 2), # 14.4 (only fwd pass)\n",
    "    (\"home_desktop\", \"OMP_CPU3\", 2), # 14.4\n",
    "    (\"home_desktop\", \"OMP_CPU7\", 2), # 14.4\n",
    "    \n",
    "    (\"DAS5\", \"OMP_CPU1\", 4), # 9.6 (only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU3\", 4), # 9.6\n",
    "    (\"DAS5\", \"OMP_CPU4\", 1), # 9.6\n",
    "    (\"DAS5\", \"OMP_CPU7\", 4), # 9.6\n",
    "    \n",
    "    (\"lisa\", \"OMP_CPU1\", 4), # 8 (only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU3\", 4), # 8\n",
    "    (\"lisa\", \"OMP_CPU7\", 4), # 8\n",
    "    \n",
    "    (\"home_desktop\", \"sequential\", 1), # 7.2\n",
    "    \n",
    "    (\"DAS5\", \"OMP_CPU1\", 2), # 4.8 (only fwd pass)\n",
    "    (\"DAS5\", \"OMP_CPU3\", 2), # 4.8\n",
    "    (\"DAS5\", \"OMP_CPU7\", 2), # 4.8\n",
    "    \n",
    "    (\"lisa\", \"OMP_CPU1\", 2), # 4 (only fwd pass)\n",
    "    (\"lisa\", \"OMP_CPU3\", 2), # 4\n",
    "    (\"lisa\", \"OMP_CPU7\", 2), # 4\n",
    "    \n",
    "    (\"DAS5\", \"sequential\", 1), # 2.4\n",
    "    \n",
    "    (\"lisa\", \"sequential\", 1)  # 2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Fetch all the rankings with the same parameters. In the case of multiple, choose the first.\n",
    "predicted_rankings = defaultdict(lambda: {})\n",
    "benchmark_rankings = defaultdict(lambda: {})\n",
    "for ranking_id in rankings[\"ranking_id\"].unique():\n",
    "    for i, row in rankings[rankings[\"ranking_id\"] == ranking_id].iterrows():\n",
    "        # Extract the parameters\n",
    "        params = tuple(row.iloc[2:8])\n",
    "        \n",
    "        # If there are already with those, skip\n",
    "        if row[\"ranking_position\"] in predicted_rankings[params]:\n",
    "            continue\n",
    "        \n",
    "        # Put the ranking in the dict\n",
    "            \n",
    "        # Store this ranking\n",
    "        predicted_rankings[params][row[\"ranking_position\"]] = tuple(row.iloc[8:11])\n",
    "        benchmark_rankings[params][row[\"ranking_position\"]] = tuple(row.iloc[12:16])\n",
    "\n",
    "# Get rid of the default stuff\n",
    "predicted_rankings = {params: predicted_rankings[params] for params in predicted_rankings}\n",
    "benchmark_rankings = {params: benchmark_rankings[params] for params in benchmark_rankings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = [\"n_hidden_layers\", \"nodes_per_layer\", \"n_epochs\", \"n_samples\", \"sample_size\", \"n_classes\"]\n",
    "NAME_INDEX_MAP = {\n",
    "    \"n_hidden_layers\": 0,\n",
    "    \"nodes_per_layer\": 1,\n",
    "    \"n_epochs\": 2,\n",
    "    \"n_samples\": 3,\n",
    "    \"sample_size\": 4,\n",
    "    \"n_classes\": 5\n",
    "}\n",
    "NAME_DEFAULT_MAP = {\n",
    "    \"n_hidden_layers\" : 1,\n",
    "    \"nodes_per_layer\" : 20,\n",
    "    \"n_epochs\" : 500,\n",
    "    \"n_samples\" : 500,\n",
    "    \"sample_size\" : 50,\n",
    "    \"n_classes\" : 10\n",
    "}\n",
    "\n",
    "\n",
    "def get_by_var(data, varname):\n",
    "    \"\"\"\n",
    "        This function is able to return all rankings for a certain variable, in increasing order for that variable\n",
    "        Returns the values of all static parameters, list of (param, benchmark) pairs where each pair is first the value of the param and then the benchmark data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Search for the one all default\n",
    "    results = []\n",
    "    for params in data:\n",
    "        got_em = True\n",
    "        for i, p in enumerate(params):\n",
    "            if p != NAME_DEFAULT_MAP[NAMES[i]]:\n",
    "                got_em = False\n",
    "                break\n",
    "        if got_em:\n",
    "            results.append((NAME_DEFAULT_MAP[varname], data[params]))\n",
    "    \n",
    "    # Loop through all unique values of the column and collect those not default\n",
    "    done = []\n",
    "    for params in data:\n",
    "        # Make sure we only look at unique values\n",
    "        value = params[NAME_INDEX_MAP[varname]]\n",
    "        if value in done or value == NAME_DEFAULT_MAP[varname]: continue\n",
    "        done.append(value)\n",
    "        \n",
    "        # Store this one as well\n",
    "        results.append((value, data[params]))\n",
    "    \n",
    "    # Sort, return\n",
    "    results = sorted(results, key=lambda elem: elem[0])\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_rank(array, pair):\n",
    "    \"\"\"\n",
    "        Returns the rank of given benchmark in given list\n",
    "    \"\"\"\n",
    "    \n",
    "    for rank in range(len(array)):\n",
    "        if array[rank][:3] == pair:\n",
    "            return rank\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_quality(ranking, ground_truth, podium_size = 1):\n",
    "    \"\"\"\n",
    "        Returns the performance of a given application\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    for rank in range(len(ranking)):\n",
    "        if ranking[rank][:3] == ground_truth[rank][:3]:\n",
    "            accuracy += 1\n",
    "        total += 1\n",
    "    # Make it into an accuracy\n",
    "    accuracy = accuracy / total * 100\n",
    "\n",
    "    # Performance loss: we given the model points off for the benchmarked time of predicted best VS actual best\n",
    "    performance_loss = defaultdict(int)\n",
    "    for rank in range(min(len(ranking), podium_size)):\n",
    "        # Get the position of the actual best rank\n",
    "        predicted_best = ground_truth[get_rank(ground_truth, ranking[rank][:3])][3]\n",
    "        actual_best = ground_truth[rank][3]\n",
    "        performance_loss[rank] += abs(predicted_best - actual_best)\n",
    "        performance_loss[\"total\"] += abs(predicted_best - actual_best)\n",
    "    worst_case = ground_truth[len(ground_truth) - 1][3] - ground_truth[0][3]\n",
    "    \n",
    "    # Normalize the performance loss\n",
    "    for r in performance_loss:\n",
    "        if r == \"total\":\n",
    "            performance_loss[r] /= (worst_case * podium_size)\n",
    "        else:\n",
    "            performance_loss[r] /= worst_case\n",
    "    \n",
    "    return accuracy, performance_loss\n",
    "\n",
    "\n",
    "\n",
    "# # For every parameter set, compute metrics & print\n",
    "# xs = []\n",
    "# ys = []\n",
    "# for params in predicted_rankings:\n",
    "#     predicted = predicted_rankings[params]\n",
    "#     benchmark = benchmark_rankings[params]\n",
    "#     uninformed = uninformed_ranking\n",
    "    \n",
    "#     # Compute the accuracieshttp://localhost:8888/?token=9ebc0c833d1988c876aba1c913ebb038d8f48a93d7061dae\n",
    "#     p_accuracy = 0\n",
    "#     p_total = 0\n",
    "#     u_accuracy = 0\n",
    "#     u_total = 0\n",
    "#     for i in range(len(predicted)):\n",
    "#         if predicted[i] == benchmark[i][:3]:\n",
    "#             p_accuracy += 1\n",
    "#         if uninformed[i] == benchmark[i][:3]:\n",
    "#             u_accuracy += 1\n",
    "#         p_total += 1\n",
    "#         u_total += 1\n",
    "#     p_accuracy = p_accuracy / p_total * 100\n",
    "#     u_accuracy = u_accuracy / u_total * 100\n",
    "    \n",
    "#     # Compute the performance loss\n",
    "#     p_loss = benchmark[get_rank(benchmark, predicted[0])][3] - benchmark[0][3]\n",
    "#     u_loss = benchmark[get_rank(benchmark, uninformed[0])][3] - benchmark[0][3]\n",
    "#     p_loss /= benchmark[len(benchmark) - 1][3] - benchmark[0][3]\n",
    "#     u_loss /= benchmark[len(benchmark) - 1][3] - benchmark[0][3]\n",
    "    \n",
    "#     # Print the latex-pastable row\n",
    "#     print(f\"{params} & {u_accuracy:.2f} & {u_loss:.2f} & {p_accuracy:.2f} & {u_loss:.2f} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PARAM_NAME_MAP = {\n",
    "    \"n_hidden_layers\" : \"Number of hidden layers\",\n",
    "    \"nodes_per_layer\" : \"Number of nodes per hidden layer\",\n",
    "    \"n_epochs\" : \"Number of epochs\",\n",
    "    \"n_samples\" : \"Number of samples\",\n",
    "    \"sample_size\" : \"Number of datapoints per sample\",\n",
    "    \"n_classes\" : \"Number of classes\"\n",
    "}\n",
    "\n",
    "podium_size = 1\n",
    "ax2_limit = [0, 1]\n",
    "font_size = 14\n",
    "margin = 3\n",
    "\n",
    "# Using the functions above, we will now proceed to plot for all parameters\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "fig, ax = plt.subplots(2, 3, sharey=False, figsize=(14,9))\n",
    "fig.tight_layout(pad=margin)\n",
    "prev_ax1 = None\n",
    "prev_ax2 = None\n",
    "shared_y1 = None\n",
    "shared_y2 = None\n",
    "for i, varname in enumerate(NAMES):\n",
    "    # Acquire the data\n",
    "    predicted_data = get_by_var(predicted_ranking, varname)\n",
    "    benchmark_data = get_by_var(benchmark_ranking, varname)\n",
    "    uninformed_data = get_by_var(uninformed_ranking, varname)\n",
    "    xs = [elem[0] for elem in predicted_data]\n",
    "    ys = [elem[1] for elem in var_data]\n",
    "    ys = [get_quality(y, podium_size=podium_size) for y in ys]\n",
    "    \n",
    "    col = i % 3\n",
    "    row = i // 3\n",
    "    \n",
    "    # Create a secondary axis and share it with the first\n",
    "    ax1 = ax[row, col]\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Link the axes\n",
    "    if shared_y1 is None:\n",
    "        shared_y1 = ax1.get_shared_y_axes()\n",
    "    else:\n",
    "        shared_y1.join(prev_ax1, ax1)\n",
    "    if shared_y2 is None:\n",
    "        shared_y2 = ax2.get_shared_y_axes()\n",
    "    else:\n",
    "        shared_y2.join(prev_ax2, ax2)\n",
    "    prev_ax1 = ax1\n",
    "    prev_ax2 = ax2\n",
    "    \n",
    "    # Set ax properties\n",
    "    ax1.set_title(f\"Quality for {varname}\", loc=\"center\")\n",
    "    ax1.set_xlabel(PARAM_NAME_MAP[varname])\n",
    "    ax1.set_xticks(range(len(xs)))\n",
    "    ax1.set_xticklabels(xs)\n",
    "    ax1.set_ylim([-5,105])\n",
    "    ax1.grid()\n",
    "    if col == 0:\n",
    "        ax1.set_ylabel(\"Total accuracy (%)\")\n",
    "\n",
    "    ax2.set_ylim([ax2_limit[0] - (ax2_limit[1] - ax2_limit[0]) * 0.05, ax2_limit[1] + (ax2_limit[1] - ax2_limit[0]) * 0.05])\n",
    "    ax2.set_yticks(np.linspace(ax2_limit[0], ax2_limit[1], 6))\n",
    "    if col == 2:\n",
    "        ax2.set_ylabel(\"Relative performance loss\")\n",
    "    \n",
    "    # Change the colour of the default xtick to red\n",
    "    ax1.get_xticklabels()[xs.index(NAME_DEFAULT_MAP[varname])].set_color('red') \n",
    "    \n",
    "    # Plot the stuff\n",
    "    ln1 = ax1.plot(range(len(xs)), [y[0] for y in ys], '-o', label=\"Accuracy\")\n",
    "    text = f\"best {podium_size} ranks\" if podium_size > 1 else \"best rank\"\n",
    "    ln2 = ax2.plot(range(len(xs)), [y[1][\"total\"] for y in ys], '-o', color='orange', label=f\"Performance loss ({text})\")\n",
    "    \n",
    "    lns = [ln1[0], ln2[0]]\n",
    "    lbs = [l.get_label() for l in lns]\n",
    "    \n",
    "    fig.legend(lns, lbs, loc=\"upper center\", ncol=len(lns))\n",
    "\n",
    "# Finally, show and save\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.savefig(f\"plots/plot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
